#!/bin/env python3

import argparse
import boto3
from benchgo.transaction_tables import *
import sys

if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description="Create data and DDL for benchgo benchmarks"
    )
    parser.add_argument("--ddl", action="store_true", help="generate SQL for creating target tables")
    parser.add_argument("--table-path", default="trns_abl", help="full path to table in generated SQL")
    parser.add_argument("--data", action="store_true", help="generate data for benchmarks")
    parser.add_argument("--width-factor", default="1", help="width factor for data/ddl generation factor of 1=10 cols, factor of 10 = 100 cols, etc")
    parser.add_argument("--jobs", default="1", help="when generating data, this is the total number of parallel jobs that you will run (1 job defaults to 100,000 records)")
    parser.add_argument("--job", default="1", help="this is the job ID of THIS job")
    parser.add_argument("--records-per-job", default="100000", help="number of rows/records to generate")
    parser.add_argument("--sparsity", default="1.0", help="data sparsity in the table, e.g: 0.1 will populate aprox 10 perc of the fields")

    # Output options
    parser.add_argument("--dirout", default=None, help="place resultant CSV files in here")
    parser.add_argument("--s3out", default=None, help="place resultant CSV in this S3 bucket")
    parser.add_argument("--s3prefix", default="", help="place resultant CSV prefix")
    parser.add_argument("--access-key", help="AWS access key")
    parser.add_argument("--secret-key", help="AWS secret key")
    parser.add_argument("--endpoint", default=None, help="S3/AWS endpoint")


    parser.add_argument("--charlimit", default=1073741824, help="utf-8 character limit for files/objects, threshold for triggering a new object")

    args = parser.parse_args()

    if args.ddl:
        create_transaction_table(width_factor=int(args.width_factor), table_path=args.table_path)
    
    if args.data:
        sys.stdout.write("generating data...")
        sys.stdout.flush()
        rows = mk_data(
            args,
            width_factor=int(args.width_factor),
            jobs=int(args.jobs),
            job=int(args.job),
            sparsity=float(args.sparsity),
            multiplier=int(args.records_per_job),
            limit=int(args.charlimit)
        )
        print("done")
        

            


